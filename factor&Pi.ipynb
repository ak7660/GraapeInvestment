{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 02:36:03,625 - INFO - Loading data for BTC\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'Start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 711\u001b[0m\n\u001b[1;32m    707\u001b[0m     plot_portfolio_and_drawdown(portfolio_history, price_data)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 711\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 660\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    657\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Path to CSV files containing market cap data\u001b[39;00m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;66;03m# Load price and market cap data from CSV files\u001b[39;00m\n\u001b[0;32m--> 660\u001b[0m price_data, market_cap_data \u001b[38;5;241m=\u001b[39m \u001b[43mload_price_and_market_cap_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_10_coins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# Select Protection Strategy\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# Options: protection_strategy_sp, protection_strategy_cppi, protection_strategy_tipp, protection_strategy_vbpi\u001b[39;00m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;66;03m# Uncomment the strategy you want to test:\u001b[39;00m\n\u001b[1;32m    666\u001b[0m protection_strategy \u001b[38;5;241m=\u001b[39m protection_strategy_sp  \u001b[38;5;66;03m# Stop Protection\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 186\u001b[0m, in \u001b[0;36mload_price_and_market_cap_data\u001b[0;34m(folder_path, coins, start_date, end_date)\u001b[0m\n\u001b[1;32m    184\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStart\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Log the number of loaded rows for this coin\u001b[39;00m\n\u001b[1;32m    189\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofHongKong/year3.1/Investment/GIG/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofHongKong/year3.1/Investment/GIG/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofHongKong/year3.1/Investment/GIG/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofHongKong/year3.1/Investment/GIG/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofHongKong/year3.1/Investment/GIG/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_usecols_names(\n\u001b[1;32m    156\u001b[0m             usecols,\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_noconvert_columns()\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheUniversityofHongKong/year3.1/Investment/GIG/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:243\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m    233\u001b[0m missing_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    235\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m     )\n\u001b[1;32m    241\u001b[0m )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing column provided to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparse_dates\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m     )\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    248\u001b[0m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[1;32m    250\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'Start'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.api import OLS\n",
    "import statsmodels.api as sm\n",
    "import yfinance as yf\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "# Protection Strategy Functions\n",
    "def adjust_hedge(long_return_total, short_return_average):\n",
    "    \"\"\"\n",
    "    Adjust hedge ratio based on long and short returns.\n",
    "\n",
    "    Parameters:\n",
    "    - long_return_total (float): Total return from long positions.\n",
    "    - short_return_average (float): Average return from short positions.\n",
    "\n",
    "    Returns:\n",
    "    - hedge_ratio (float): Proportion of the portfolio to hedge.\n",
    "    \"\"\"\n",
    "    if long_return_total < short_return_average:\n",
    "        return 0.35  # Adjust this value as needed\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def protection_strategy_sp(weekly_return, long_return_total, short_return_average):\n",
    "    \"\"\"\n",
    "    Stop Protection (SP) strategy to adjust weekly returns based on hedge ratio.\n",
    "\n",
    "    Parameters:\n",
    "    - weekly_return (float): Original weekly return.\n",
    "    - long_return_total (float): Total return from long positions.\n",
    "    - short_return_average (float): Average return from short positions.\n",
    "\n",
    "    Returns:\n",
    "    - adjusted_weekly_return (float): Adjusted weekly return after applying SP.\n",
    "    \"\"\"\n",
    "    hedge_ratio = adjust_hedge(long_return_total, short_return_average)\n",
    "    adjusted_weekly_return = long_return_total * (1 - hedge_ratio) - short_return_average\n",
    "    logging.info(f\"SP Strategy Applied: Hedge Ratio = {hedge_ratio}, Adjusted Weekly Return = {adjusted_weekly_return:.4f}\")\n",
    "    return adjusted_weekly_return\n",
    "\n",
    "\n",
    "def protection_strategy_cppi(portfolio_value, floor, multiplier, weekly_return):\n",
    "    \"\"\"\n",
    "    Constant Proportion Portfolio Insurance (CPPI) strategy implementation.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio_value (float): Current portfolio value.\n",
    "    - floor (float): Minimum acceptable portfolio value.\n",
    "    - multiplier (float): Determines the exposure to risky assets.\n",
    "    - weekly_return (float): Original weekly return.\n",
    "\n",
    "    Returns:\n",
    "    - adjusted_weekly_return (float): Adjusted weekly return after applying CPPI.\n",
    "    \"\"\"\n",
    "    # Calculate the cushion\n",
    "    cushion = portfolio_value - floor\n",
    "\n",
    "    # Determine exposure to risky assets\n",
    "    investment_risky = cushion * multiplier\n",
    "    investment_risky = min(investment_risky, portfolio_value)  # Ensure not to exceed portfolio\n",
    "\n",
    "    # Allocation to safe assets\n",
    "    investment_safe = portfolio_value - investment_risky\n",
    "\n",
    "    # Calculate returns\n",
    "    # Assuming weekly_return represents the return from risky assets\n",
    "    risky_return = investment_risky * weekly_return\n",
    "    safe_return = investment_safe * 0.0  # Assuming safe assets have 0% return\n",
    "\n",
    "    # Total adjusted return\n",
    "    adjusted_weekly_return = (risky_return + safe_return) / portfolio_value\n",
    "    logging.info(f\"CPPI Strategy Applied: Cushion = {cushion:.2f}, Investment Risky = {investment_risky:.2f}, \"\n",
    "                 f\"Investment Safe = {investment_safe:.2f}, Adjusted Weekly Return = {adjusted_weekly_return:.4f}\")\n",
    "    return adjusted_weekly_return\n",
    "\n",
    "\n",
    "def protection_strategy_tipp(weekly_return, long_return_total, short_return_average, base_allocation=0.5):\n",
    "    \"\"\"\n",
    "    Time-Invariant Portfolio Protection (TIPP) strategy implementation.\n",
    "\n",
    "    Parameters:\n",
    "    - weekly_return (float): Original weekly return.\n",
    "    - long_return_total (float): Total return from long positions.\n",
    "    - short_return_average (float): Average return from short positions.\n",
    "    - base_allocation (float): Fixed allocation to risky assets.\n",
    "\n",
    "    Returns:\n",
    "    - adjusted_weekly_return (float): Adjusted weekly return after applying TIPP.\n",
    "    \"\"\"\n",
    "    # TIPP maintains a fixed allocation to risky assets regardless of performance\n",
    "    # base_allocation determines the proportion allocated to risky assets\n",
    "    investment_risky = base_allocation\n",
    "    investment_safe = 1 - base_allocation\n",
    "\n",
    "    adjusted_weekly_return = (investment_risky * weekly_return) + (investment_safe * 0.0)  # Safe assets have 0% return\n",
    "    logging.info(f\"TIPP Strategy Applied: Investment Risky = {investment_risky:.2f}, \"\n",
    "                 f\"Investment Safe = {investment_safe:.2f}, Adjusted Weekly Return = {adjusted_weekly_return:.4f}\")\n",
    "    return adjusted_weekly_return\n",
    "\n",
    "\n",
    "def protection_strategy_vbpi(portfolio_value, volatility, threshold=0.05, base_allocation=0.5, max_allocation=1.0, min_allocation=0.0):\n",
    "    \"\"\"\n",
    "    Volatility-Based Portfolio Insurance (VBPI) strategy implementation.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio_value (float): Current portfolio value.\n",
    "    - volatility (float): Current market volatility (e.g., standard deviation of returns).\n",
    "    - threshold (float): Volatility threshold to adjust allocations.\n",
    "    - base_allocation (float): Base allocation to risky assets at normal volatility.\n",
    "    - max_allocation (float): Maximum allocation to risky assets during low volatility.\n",
    "    - min_allocation (float): Minimum allocation to risky assets during high volatility.\n",
    "\n",
    "    Returns:\n",
    "    - adjusted_weekly_return (float): Adjusted weekly return after applying VBPI.\n",
    "    \"\"\"\n",
    "    # Adjust allocation based on volatility\n",
    "    if volatility > threshold:\n",
    "        # High volatility: reduce exposure to risky assets\n",
    "        allocation_risky = min_allocation\n",
    "    else:\n",
    "        # Low or normal volatility: increase exposure to risky assets\n",
    "        allocation_risky = min(base_allocation + (threshold - volatility), max_allocation)\n",
    "    \n",
    "    allocation_safe = 1 - allocation_risky\n",
    "\n",
    "    # For VBPI, we might need a return based on allocation\n",
    "    adjusted_weekly_return = (allocation_risky * weekly_return) + (allocation_safe * 0.0)  # Safe assets have 0% return\n",
    "    logging.info(f\"VBPI Strategy Applied: Allocation Risky = {allocation_risky:.2f}, \"\n",
    "                 f\"Allocation Safe = {allocation_safe:.2f}, Adjusted Weekly Return = {adjusted_weekly_return:.4f}\")\n",
    "    return adjusted_weekly_return\n",
    "\n",
    "\n",
    "# Rebalancing Function\n",
    "def rebalancing(portfolio, target_allocation):\n",
    "    \"\"\"\n",
    "    Rebalance the portfolio to match the target allocation.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio (dict): Current portfolio with asset allocations.\n",
    "    - target_allocation (dict): Target allocation percentages.\n",
    "\n",
    "    Returns:\n",
    "    - portfolio (dict): Rebalanced portfolio.\n",
    "    \"\"\"\n",
    "    total_value = sum(portfolio.values())\n",
    "    for asset, allocation in target_allocation.items():\n",
    "        portfolio[asset] = total_value * allocation\n",
    "    logging.info(f\"Portfolio rebalanced: {portfolio}\")\n",
    "    return portfolio\n",
    "\n",
    "\n",
    "# Load Price and Market Cap Data\n",
    "def load_price_and_market_cap_data(folder_path, coins, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Load price and market cap data from CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_path (str): Path to CSV files.\n",
    "    - coins (list): List of cryptocurrency symbols.\n",
    "    - start_date (str): Start date for the data.\n",
    "    - end_date (str): End date for the data.\n",
    "\n",
    "    Returns:\n",
    "    - price_data (pd.DataFrame): DataFrame of close prices.\n",
    "    - market_cap_data (dict): Dictionary of market cap and volume data.\n",
    "    \"\"\"\n",
    "    price_data = {}\n",
    "    market_cap_data = {}\n",
    "\n",
    "    for coin in coins:\n",
    "        logging.info(f\"Loading data for {coin}\")\n",
    "        file_path = os.path.join(folder_path, f\"{coin}.csv\")\n",
    "        if not os.path.exists(file_path):\n",
    "            logging.error(f\"File not found: {file_path}\")\n",
    "            continue\n",
    "        df = pd.read_csv(file_path, parse_dates=['Start'], index_col='Start')\n",
    "\n",
    "        # Log the number of loaded rows for this coin\n",
    "        logging.info(f\"Loaded {len(df)} rows for {coin}\")\n",
    "\n",
    "        # Store close prices for price data\n",
    "        price_data[coin] = df['Close']\n",
    "\n",
    "        # Store market cap data\n",
    "        market_cap_data[coin] = df[['Market Cap', 'Volume']]\n",
    "\n",
    "    # Convert dictionaries to DataFrames\n",
    "    price_data = pd.DataFrame(price_data)\n",
    "\n",
    "    # Handle missing values in price data (forward fill or drop)\n",
    "    logging.info(\"Forward filling and dropping NaN values in the price data.\")\n",
    "    price_data.ffill(inplace=True)  # Forward fill missing values\n",
    "    price_data.dropna(inplace=True)  # Drop rows with persistent NaN values\n",
    "\n",
    "    # Log the date range of the price data\n",
    "    logging.info(f\"Price Data Date Range: {price_data.index.min()} to {price_data.index.max()}\")\n",
    "\n",
    "    # Check if we have data for the required backtest period\n",
    "    if price_data.index.min() > pd.to_datetime(start_date) or price_data.index.max() < pd.to_datetime(end_date):\n",
    "        logging.warning(f\"Price data does not cover the full backtest period from {start_date} to {end_date}\")\n",
    "\n",
    "    # Convert market_cap_data to proper DataFrames\n",
    "    market_cap_data = {coin: df for coin, df in market_cap_data.items()}\n",
    "\n",
    "    logging.info(f\"Price Data Head:\\n{price_data.head()}\")\n",
    "    return price_data, market_cap_data\n",
    "\n",
    "\n",
    "# Factor Calculation\n",
    "def calculate_factors(price_data, cap_data, rolling_window=7):\n",
    "    \"\"\"\n",
    "    Calculate Momentum, Size, and Value factors.\n",
    "\n",
    "    Parameters:\n",
    "    - price_data (pd.DataFrame): DataFrame of close prices.\n",
    "    - cap_data (dict): Dictionary of market cap and volume data.\n",
    "    - rolling_window (int): Rolling window for momentum calculation.\n",
    "\n",
    "    Returns:\n",
    "    - momentum (pd.DataFrame): Momentum factor.\n",
    "    - size (pd.DataFrame): Size factor (market cap).\n",
    "    - value (pd.DataFrame): Value factor (inverse of NVT ratio).\n",
    "    \"\"\"\n",
    "    logging.info(\"Calculating factors (Momentum, Size, Value)\")\n",
    "\n",
    "    # Momentum: past week return\n",
    "    momentum = price_data.pct_change(rolling_window).shift(1)\n",
    "    logging.info(f\"Momentum head:\\n{momentum.head()}\")\n",
    "\n",
    "    # Size: market cap of the coins\n",
    "    size = pd.DataFrame({coin: cap_data[coin]['Market Cap'] for coin in cap_data})\n",
    "    logging.info(f\"Size head:\\n{size.head()}\")\n",
    "\n",
    "    # Value: inverse of NVT ratio (Market Cap / Volume)\n",
    "    value = pd.DataFrame({coin: cap_data[coin]['Market Cap'] / cap_data[coin]['Volume'] for coin in cap_data})\n",
    "\n",
    "    # Handle potential divide-by-zero or inf values in NVT ratio\n",
    "    value.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace inf values with NaN\n",
    "    value.fillna(0, inplace=True)  # Replace NaN values with 0 or another strategy\n",
    "    logging.info(f\"Value (NVT) head before inversion:\\n{value.head()}\")\n",
    "\n",
    "    value = 1 / value\n",
    "    value = value.clip(lower=-1e9, upper=1e9)  # Clip values to a reasonable range\n",
    "    logging.info(f\"Value (after inversion and clipping) head:\\n{value.head()}\")\n",
    "\n",
    "    return momentum, size, value\n",
    "\n",
    "\n",
    "# Backtest Strategy\n",
    "def backtest_strategy(start_date, end_date, initial_investment, price_data, cap_data, \n",
    "                     protection_strategy, \n",
    "                     floor_ratio=0.9, \n",
    "                     multiplier=3, \n",
    "                     threshold=0.05, \n",
    "                     base_allocation_tipp=0.5, \n",
    "                     max_allocation_vbpi=1.0, \n",
    "                     min_allocation_vbpi=0.0,\n",
    "                     rebalance_time='00:00'):\n",
    "    \"\"\"\n",
    "    Backtest the crypto strategy with dynamic long/short and protection strategy.\n",
    "\n",
    "    Parameters:\n",
    "    - start_date (str): Start date of the backtest in 'YYYY-MM-DD' format.\n",
    "    - end_date (str): End date of the backtest in 'YYYY-MM-DD' format.\n",
    "    - initial_investment (float): Initial portfolio value in USD.\n",
    "    - price_data (pd.DataFrame): DataFrame of close prices.\n",
    "    - cap_data (dict): Dictionary of market cap and volume data.\n",
    "    - protection_strategy (function): Function to apply protection strategy.\n",
    "    - floor_ratio (float): Ratio to determine the floor (e.g., 0.9 for 90% of initial investment).\n",
    "    - multiplier (float): Multiplier for CPPI strategy.\n",
    "    - threshold (float): Volatility threshold for VBPI strategy.\n",
    "    - base_allocation_tipp (float): Base allocation for TIPP strategy.\n",
    "    - max_allocation_vbpi (float): Max allocation to risky assets for VBPI.\n",
    "    - min_allocation_vbpi (float): Min allocation to risky assets for VBPI.\n",
    "    - rebalance_time (str): Time of day to perform rebalancing.\n",
    "\n",
    "    Returns:\n",
    "    - portfolio_history_df (pd.DataFrame): DataFrame containing portfolio values indexed by date.\n",
    "    - returns_history (list): List of weekly returns.\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting backtest\")\n",
    "    # Initialize portfolio metrics\n",
    "    portfolio_value = initial_investment\n",
    "    portfolio_history = []\n",
    "    returns_history = []\n",
    "\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='W-SUN')\n",
    "    logging.info(f\"Backtest dates: {dates}\")\n",
    "\n",
    "    # Calculate floor based on initial investment\n",
    "    floor = initial_investment * floor_ratio\n",
    "\n",
    "    # Calculate factors\n",
    "    momentum, size, value = calculate_factors(price_data, cap_data)\n",
    "\n",
    "    # Standardize factors (handle NaN and inf values)\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Apply StandardScaler while handling NaN values\n",
    "    logging.info(\"Standardizing factors.\")\n",
    "    momentum_std = pd.DataFrame(scaler.fit_transform(momentum.fillna(0)), index=momentum.index, columns=momentum.columns)\n",
    "    size_std = pd.DataFrame(scaler.fit_transform(size.fillna(0)), index=size.index, columns=size.columns)\n",
    "    value_std = pd.DataFrame(scaler.fit_transform(value.fillna(0)), index=value.index, columns=value.columns)\n",
    "\n",
    "    # Combine factors (equal weight)\n",
    "    combined_signal = (momentum_std + size_std + value_std) / 3\n",
    "    logging.info(f\"Combined signal head:\\n{combined_signal.head()}\")\n",
    "\n",
    "    # Restrict signals to the backtest period (starting from start_date)\n",
    "    combined_signal = combined_signal.loc[start_date:end_date]\n",
    "\n",
    "    for date in dates:\n",
    "        # Use only the date without time\n",
    "        portfolio_date = date\n",
    "        logging.info(f\"Rebalancing for date: {portfolio_date.date()}\")\n",
    "\n",
    "        if portfolio_date in combined_signal.index:\n",
    "            signals = combined_signal.loc[portfolio_date]\n",
    "            logging.info(f\"Signals on {portfolio_date.date()}:\\n{signals}\")\n",
    "\n",
    "            # Check if there are any valid signals\n",
    "            if signals.isna().all():\n",
    "                logging.warning(f\"No valid signals on {portfolio_date.date()}. Skipping this date.\")\n",
    "                # Append current portfolio value and zero return\n",
    "                portfolio_history.append(portfolio_value)\n",
    "                returns_history.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Split signals dynamically based on their strength\n",
    "            long_threshold = 0.5  # Go long if signal > 0.5\n",
    "            short_threshold = -0.5  # Go short if signal < -0.5\n",
    "\n",
    "            # Dynamic long/short allocation based on signal strength\n",
    "            long_coins = signals[signals > long_threshold].index\n",
    "            short_coins = signals[signals < short_threshold].index\n",
    "\n",
    "            # If no strong short signals, skip shorting\n",
    "            if len(short_coins) == 0:\n",
    "                logging.info(f\"No strong short signals on {portfolio_date.date()}. Not shorting.\")\n",
    "\n",
    "            # If no strong long signals, skip longing\n",
    "            if len(long_coins) == 0:\n",
    "                logging.info(f\"No strong long signals on {portfolio_date.date()}. Not longing.\")\n",
    "\n",
    "            # Ensure there are coins to long or short\n",
    "            if len(long_coins) == 0 and len(short_coins) == 0:\n",
    "                logging.warning(f\"No strong signals to act upon on {portfolio_date.date()}. Skipping.\")\n",
    "                portfolio_history.append(portfolio_value)\n",
    "                returns_history.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Compute value-weighted allocation\n",
    "            total_market_cap = size.loc[portfolio_date, long_coins].sum() if len(long_coins) > 0 else 1\n",
    "            weights = size.loc[portfolio_date, long_coins] / total_market_cap if len(long_coins) > 0 else pd.Series(0, index=long_coins)\n",
    "\n",
    "            # Log market cap and weights for long positions\n",
    "            logging.info(f\"Market cap for long coins:\\n{size.loc[portfolio_date, long_coins]}\")\n",
    "            logging.info(f\"Weights for long positions:\\n{weights}\")\n",
    "\n",
    "            try:\n",
    "                # Find the next trading day after portfolio_date\n",
    "                future_dates = price_data.index[price_data.index > portfolio_date]\n",
    "                if future_dates.empty:\n",
    "                    logging.warning(f\"No future price data available after {portfolio_date.date()}. Skipping return calculation.\")\n",
    "                    portfolio_history.append(portfolio_value)\n",
    "                    returns_history.append(0.0)\n",
    "                    continue\n",
    "                next_date = future_dates[0]\n",
    "\n",
    "                # Ensure next_date is within the price_data index\n",
    "                if next_date not in price_data.index:\n",
    "                    logging.warning(f\"No price data for the next day after {portfolio_date.date()}. Skipping return calculation.\")\n",
    "                    portfolio_history.append(portfolio_value)\n",
    "                    returns_history.append(0.0)\n",
    "                    continue\n",
    "\n",
    "                # Calculate long returns\n",
    "                long_price_current = price_data.loc[portfolio_date, long_coins]\n",
    "                long_price_next = price_data.loc[next_date, long_coins]\n",
    "                long_returns = (long_price_next / long_price_current - 1) * weights\n",
    "                long_return_total = long_returns.sum()\n",
    "\n",
    "                # Calculate short returns\n",
    "                short_return_total = 0.0\n",
    "                if len(short_coins) > 0:\n",
    "                    short_price_current = price_data.loc[portfolio_date, short_coins]\n",
    "                    short_price_next = price_data.loc[next_date, short_coins]\n",
    "                    short_returns = (short_price_next / short_price_current - 1)\n",
    "                    short_return_total = short_returns.mean() if not short_returns.empty else 0.0\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error calculating returns: {e}\")\n",
    "                portfolio_history.append(portfolio_value)\n",
    "                returns_history.append(0.0)\n",
    "                continue\n",
    "\n",
    "            # Calculate original weekly return\n",
    "            original_weekly_return = long_return_total - short_return_total\n",
    "            logging.info(f\"Original Weekly Return: {original_weekly_return:.4f}\")\n",
    "\n",
    "            # Apply protection strategy\n",
    "            if protection_strategy.__name__ == 'protection_strategy_cppi':\n",
    "                adjusted_weekly_return = protection_strategy(\n",
    "                    portfolio_value, floor, multiplier, original_weekly_return\n",
    "                )\n",
    "            elif protection_strategy.__name__ == 'protection_strategy_vbpi':\n",
    "                # Calculate volatility (e.g., standard deviation of past 4 weeks' returns)\n",
    "                window_volatility = 4\n",
    "                if len(returns_history) >= window_volatility:\n",
    "                    recent_returns = returns_history[-window_volatility:]\n",
    "                    volatility = np.std(recent_returns)\n",
    "                else:\n",
    "                    volatility = 0.0  # Assume low volatility if not enough data\n",
    "                adjusted_weekly_return = protection_strategy(\n",
    "                    portfolio_value, volatility, threshold, \n",
    "                    base_allocation=0.5,  # base_allocation can be parameterized as needed\n",
    "                    max_allocation=max_allocation_vbpi,\n",
    "                    min_allocation=min_allocation_vbpi\n",
    "                )\n",
    "            elif protection_strategy.__name__ == 'protection_strategy_tipp':\n",
    "                adjusted_weekly_return = protection_strategy(\n",
    "                    original_weekly_return, long_return_total, short_return_total, \n",
    "                    base_allocation=base_allocation_tipp\n",
    "                )\n",
    "            else:\n",
    "                # Default to SP if unknown strategy\n",
    "                adjusted_weekly_return = protection_strategy(original_weekly_return, long_return_total, short_return_total)\n",
    "\n",
    "            # Update portfolio value\n",
    "            portfolio_value *= (1 + adjusted_weekly_return)\n",
    "\n",
    "            logging.info(f\"Adjusted Weekly Return: {adjusted_weekly_return:.4f}\")\n",
    "            logging.info(f\"Updated portfolio value: {portfolio_value:.2f}\")\n",
    "\n",
    "            # Record portfolio history\n",
    "            portfolio_history.append(portfolio_value)\n",
    "            returns_history.append(adjusted_weekly_return)\n",
    "        else:\n",
    "            logging.warning(f\"No signal data for {portfolio_date.date()}. Skipping.\")\n",
    "            portfolio_history.append(portfolio_value)\n",
    "            returns_history.append(0.0)\n",
    "\n",
    "    # Convert history to DataFrame\n",
    "    if portfolio_history:\n",
    "        portfolio_history_df = pd.DataFrame(portfolio_history, index=dates, columns=['Portfolio Value'])\n",
    "    else:\n",
    "        logging.warning(\"No portfolio history recorded.\")\n",
    "        portfolio_history_df = pd.DataFrame(columns=['Portfolio Value'], index=dates)\n",
    "\n",
    "    return portfolio_history_df, returns_history\n",
    "\n",
    "\n",
    "# Performance Metrics\n",
    "def calculate_metrics(portfolio_history, returns_history, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Calculate Sharpe Ratio, Beta, and Alpha for the backtested portfolio.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio_history (pd.DataFrame): DataFrame containing portfolio values indexed by date.\n",
    "    - returns_history (list): List of weekly returns.\n",
    "    - start_date (str): Start date of the backtest in 'YYYY-MM-DD' format.\n",
    "    - end_date (str): End date of the backtest in 'YYYY-MM-DD' format.\n",
    "\n",
    "    Returns:\n",
    "    - sharpe_ratio (float): Annualized Sharpe Ratio.\n",
    "    - beta (float): Beta of the portfolio relative to BTC.\n",
    "    - alpha (float): Alpha of the portfolio.\n",
    "    \"\"\"\n",
    "    # Convert returns_history to a pandas Series with backtest dates as index\n",
    "    backtest_dates = pd.date_range(start=start_date, end=end_date, freq='W-SUN')\n",
    "    returns_series = pd.Series(returns_history, index=backtest_dates)\n",
    "    logging.info(f\"Backtest dates index for returns_series:\\n{returns_series.index}\")\n",
    "\n",
    "    # Calculate Sharpe Ratio\n",
    "    returns_cleaned = returns_series.dropna()  # Drop NaN values\n",
    "    logging.info(f\"Cleaned returns history: {returns_cleaned}\")\n",
    "\n",
    "    if len(returns_cleaned) == 0:\n",
    "        logging.warning(\"No returns to calculate metrics.\")\n",
    "        return np.nan, np.nan, np.nan\n",
    "\n",
    "    sharpe_ratio = np.mean(returns_cleaned) / np.std(returns_cleaned) * np.sqrt(52)  # Annualized Sharpe Ratio (52 weeks)\n",
    "\n",
    "    # Fetch BTC data using yfinance\n",
    "    btc_ticker = 'BTC-USD'\n",
    "    logging.info(f\"Fetching BTC data from {start_date} to {end_date} using yfinance.\")\n",
    "\n",
    "    try:\n",
    "        btc_data = yf.download(btc_ticker, start=start_date, end=end_date, progress=False)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching BTC data: {e}\")\n",
    "        return sharpe_ratio, np.nan, np.nan\n",
    "\n",
    "    if btc_data.empty:\n",
    "        logging.error(\"Fetched BTC data is empty. Please check the ticker and date range.\")\n",
    "        return sharpe_ratio, np.nan, np.nan\n",
    "\n",
    "    # Ensure the data is sorted in ascending order\n",
    "    btc_data.sort_index(inplace=True)\n",
    "    logging.info(\"Sorted BTC data in ascending order.\")\n",
    "\n",
    "    # Calculate daily returns\n",
    "    market_returns_daily = btc_data['Close'].pct_change().dropna()\n",
    "\n",
    "    # Resample daily market returns to weekly returns (W-SUN) by compounding\n",
    "    market_returns_weekly = market_returns_daily.resample('W-SUN').agg(lambda x: (1 + x).prod() - 1)\n",
    "    logging.info(f\"Weekly market returns from {start_date} to {end_date}:\\n{market_returns_weekly.head()}\")\n",
    "\n",
    "    # Align the indices of returns_history and market_returns_weekly using common dates\n",
    "    common_dates = returns_series.index.intersection(market_returns_weekly.index)\n",
    "    aligned_returns_history = returns_series.loc[common_dates]\n",
    "    aligned_market_returns = market_returns_weekly.loc[common_dates]\n",
    "\n",
    "    logging.info(f\"Common dates after intersection: {common_dates}\")\n",
    "    logging.info(f\"Aligned returns history after intersect:\\n{aligned_returns_history}\")\n",
    "    logging.info(f\"Aligned market returns after intersect:\\n{aligned_market_returns}\")\n",
    "\n",
    "    # Ensure both series have no NaN values\n",
    "    aligned_returns_history = aligned_returns_history.dropna()\n",
    "    aligned_market_returns = aligned_market_returns.dropna()\n",
    "\n",
    "    # Re-align indices to ensure they match exactly\n",
    "    common_dates_final = aligned_returns_history.index.intersection(aligned_market_returns.index)\n",
    "    aligned_returns_history = aligned_returns_history.loc[common_dates_final]\n",
    "    aligned_market_returns = market_returns_weekly.loc[common_dates_final]\n",
    "\n",
    "    logging.info(f\"Final common dates after re-intersection: {common_dates_final}\")\n",
    "    logging.info(f\"Final aligned returns history:\\n{aligned_returns_history}\")\n",
    "    logging.info(f\"Final aligned market returns:\\n{aligned_market_returns}\")\n",
    "\n",
    "    # Check if we have enough data to run the regression\n",
    "    if len(aligned_returns_history) < 2:\n",
    "        logging.warning(\"Not enough data for regression.\")\n",
    "        return sharpe_ratio, np.nan, np.nan\n",
    "\n",
    "    # Convert data to float to avoid dtype issues\n",
    "    aligned_returns_history = aligned_returns_history.astype(float)\n",
    "    aligned_market_returns = aligned_market_returns.astype(float)\n",
    "\n",
    "    # Calculate Beta and Alpha using OLS regression\n",
    "    X = sm.add_constant(aligned_market_returns)  # Adds a constant term to the predictor\n",
    "    model = OLS(aligned_returns_history, X).fit()\n",
    "    beta = model.params[aligned_market_returns.name]\n",
    "    alpha = model.params['const']\n",
    "\n",
    "    # Optionally, log the regression summary for debugging\n",
    "    logging.debug(model.summary())\n",
    "\n",
    "    return sharpe_ratio, beta, alpha\n",
    "\n",
    "\n",
    "# Plot Portfolio\n",
    "def plot_portfolio(portfolio_history):\n",
    "    \"\"\"\n",
    "    Plot the portfolio value over time.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio_history (pd.DataFrame): DataFrame containing portfolio values indexed by date.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(portfolio_history.index, portfolio_history['Portfolio Value'], label='Portfolio Value')\n",
    "    plt.title('Portfolio Value Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Equity Drawdown Calculation and Plot\n",
    "def plot_equity_drawdown(portfolio_history):\n",
    "    \"\"\"\n",
    "    Plot the equity drawdown over time.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio_history (pd.DataFrame): DataFrame containing portfolio values indexed by date.\n",
    "    \"\"\"\n",
    "    portfolio_history['Max Value'] = portfolio_history['Portfolio Value'].cummax()\n",
    "    portfolio_history['Drawdown'] = (portfolio_history['Portfolio Value'] - portfolio_history['Max Value']) / portfolio_history['Max Value']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(portfolio_history.index, portfolio_history['Drawdown'], label='Drawdown', color='red')\n",
    "    plt.fill_between(portfolio_history.index, portfolio_history['Drawdown'], color='red', alpha=0.3)\n",
    "    plt.title('Equity Drawdown Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Drawdown (%)')\n",
    "    plt.axhline(0, color='black', linestyle='--')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Daily Returns on Assets Calculation and Plot\n",
    "def plot_daily_returns_on_assets(price_data):\n",
    "    \"\"\"\n",
    "    Plot the daily returns on assets over time.\n",
    "\n",
    "    Parameters:\n",
    "    - price_data (pd.DataFrame): DataFrame containing historical prices for each cryptocurrency indexed by date.\n",
    "    \"\"\"\n",
    "    daily_returns = price_data.pct_change().dropna()  # Calculate daily returns\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.plot(daily_returns.index, daily_returns)\n",
    "    plt.title('Daily Returns on Assets')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Daily Return (%)')\n",
    "    plt.grid(True)\n",
    "    plt.legend(price_data.columns, loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot Portfolio Value with Drawdown and Daily Returns\n",
    "def plot_portfolio_and_drawdown(portfolio_history, price_data):\n",
    "    \"\"\"\n",
    "    Plot both the portfolio value and the equity drawdown over time.\n",
    "\n",
    "    Parameters:\n",
    "    - portfolio_history (pd.DataFrame): DataFrame containing portfolio values indexed by date.\n",
    "    - price_data (pd.DataFrame): DataFrame containing historical prices for each cryptocurrency.\n",
    "    \"\"\"\n",
    "    # Plot portfolio value over time\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(portfolio_history.index, portfolio_history['Portfolio Value'], label='Portfolio Value')\n",
    "    plt.title('Portfolio Value Over Time')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Portfolio Value (USD)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot equity drawdown\n",
    "    plot_equity_drawdown(portfolio_history)\n",
    "\n",
    "    # Plot daily returns on assets\n",
    "    plot_daily_returns_on_assets(price_data)\n",
    "\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    # Parameters\n",
    "    start_date = \"2021-10-01\"\n",
    "    end_date = \"2024-09-29\"  # Ensure yfinance has data up to this date\n",
    "    initial_investment = 100_000_000  # 100M USD\n",
    "\n",
    "    # Load data for top 10 cryptocurrencies (excluding USDT and USDC)\n",
    "    top_10_coins = ['BTC', 'ETH', 'BNB', 'XRP', 'ADA', 'DOGE', 'SOL', 'TON', 'TRX', 'AVAX']\n",
    "    folder_path = 'Data'  # Path to CSV files containing market cap data\n",
    "\n",
    "    # Load price and market cap data from CSV files\n",
    "    price_data, market_cap_data = load_price_and_market_cap_data(folder_path, top_10_coins, start_date, end_date)\n",
    "\n",
    "    # Select Protection Strategy\n",
    "    # Options: protection_strategy_sp, protection_strategy_cppi, protection_strategy_tipp, protection_strategy_vbpi\n",
    "    # Uncomment the strategy you want to test:\n",
    "\n",
    "    protection_strategy = protection_strategy_sp  # Stop Protection\n",
    "    #protection_strategy = protection_strategy_cppi  # CPPI Strategy\n",
    "    #protection_strategy = protection_strategy_tipp  # TIPP Strategy\n",
    "    # protection_strategy = protection_strategy_vbpi  # VBPI Strategy\n",
    "\n",
    "    # Define CPPI Parameters (only relevant if CPPI is selected)\n",
    "    floor_ratio = 0.9  # 90% floor\n",
    "    multiplier = 3  # CPPI multiplier\n",
    "\n",
    "    # Define VBPI Parameters (only relevant if VBPI is selected)\n",
    "    threshold = 0.1  # Volatility threshold\n",
    "    base_allocation_vbpi = 0.5  # Base allocation to risky assets\n",
    "    max_allocation_vbpi = 1.0  # Max allocation to risky assets\n",
    "    min_allocation_vbpi = 0.0  # Min allocation to risky assets\n",
    "\n",
    "    # Define TIPP Parameters (only relevant if TIPP is selected)\n",
    "    base_allocation_tipp = 0.75  # Fixed allocation to risky assets\n",
    "\n",
    "    # Backtest the strategy\n",
    "    portfolio_history, returns_history = backtest_strategy(\n",
    "        start_date, \n",
    "        end_date, \n",
    "        initial_investment, \n",
    "        price_data, \n",
    "        market_cap_data, \n",
    "        protection_strategy,\n",
    "        floor_ratio=floor_ratio,\n",
    "        multiplier=multiplier,\n",
    "        threshold=threshold,\n",
    "        base_allocation_tipp=base_allocation_tipp,\n",
    "        max_allocation_vbpi=max_allocation_vbpi,\n",
    "        min_allocation_vbpi=min_allocation_vbpi\n",
    "    )\n",
    "\n",
    "    # Calculate performance metrics\n",
    "    sharpe_ratio, beta, alpha = calculate_metrics(portfolio_history, returns_history, start_date, end_date)\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.4f}\")\n",
    "    print(f\"Beta: {beta:.4f}\")\n",
    "    print(f\"Alpha: {alpha:.4f}\")\n",
    "\n",
    "    # Plot portfolio value, equity drawdown, and daily returns on assets\n",
    "    plot_portfolio_and_drawdown(portfolio_history, price_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "djangoBlog3-eToprVME",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
